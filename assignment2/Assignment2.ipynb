{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvigâ€™s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Norvig's solution"
      ],
      "metadata": {
        "id": "UfH7BU5kgW3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('big.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())):\n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word):\n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word):\n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words):\n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word):\n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "metadata": {
        "id": "aRNpwrZ8Atn9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spelling_corrector_norvig(sentence):\n",
        "    sentence_arr = sentence.lower().split()\n",
        "    new_sentence = []\n",
        "    for word in sentence_arr:\n",
        "        new_sentence.append(correction(word))\n",
        "    return ' '.join(new_sentence)"
      ],
      "metadata": {
        "id": "mkSCLI4Aoniv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### My solution"
      ],
      "metadata": {
        "id": "zPaNc3rWa9jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_dict = {} # {(first_word, second_word): frequency, ...}\n",
        "vocab_check = [] # [(first_word, ' '), (' ', second_word), ...]"
      ],
      "metadata": {
        "id": "1aYRG0nOD2Qt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bigrams.txt', 'r', encoding='latin-1') as file:\n",
        "    for line in file:\n",
        "        line = line[:-1].lower().split('\\t')\n",
        "        bigram_dict[(line[1], line[2])] = int(line[0])\n",
        "        vocab_check.append((line[1], ' '))\n",
        "        vocab_check.append((' ', line[2]))"
      ],
      "metadata": {
        "id": "qWYnLTRgCz9O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_check_dict = Counter(vocab_check)"
      ],
      "metadata": {
        "id": "lFlsuRi5CJOq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function uses the 'know()', 'edits1()' and 'edits2()' functions from Norvig's solution to optimize time\n",
        "def candidates_word(word, mode=1):\n",
        "    \"\"\"\n",
        "    Generate possible spelling corrections for a words based on the entered word and mode.\n",
        "\n",
        "    Parameters:\n",
        "        word (str): The input word.\n",
        "        mode (int): The mode for generating candidates.\n",
        "                    1 - Generate candidates with one correction.\n",
        "                    2 - Generate candidates with two corrections.\n",
        "\n",
        "    Returns:\n",
        "        list: List of candidate words.\n",
        "    \"\"\"\n",
        "\n",
        "    candidates = list(known(edits1(word)))\n",
        "    if mode == 2:\n",
        "        candidates.extend(list(known(edits2(word))))\n",
        "    if known([word]):\n",
        "        # If such a word exists, add it\n",
        "        candidates.append(word)\n",
        "    if not candidates and mode == 2:\n",
        "        # If no candidates found and mode is 2, return the original word itself\n",
        "        return [word]\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "8WWogQV20s90"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  takes into account the position of the word\n",
        "def variants_word_calculate(variants, place):\n",
        "    \"\"\"\n",
        "    Filter variants based on their position in the vocabulary.\n",
        "\n",
        "    Parameters:\n",
        "        variants (list): List of word variants.\n",
        "        place (int): Position indicator.\n",
        "                     1 - Variant appears as the first word.\n",
        "                     2 - Variant appears as the second word.\n",
        "\n",
        "    Returns:\n",
        "        list: Filtered list of word variants based on their position in the vocabulary.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for variant in variants:\n",
        "        if place == 1:\n",
        "            if (variant, ' ') in vocab_check:\n",
        "                out.append(variant)\n",
        "        else:\n",
        "            if (' ', variant) in vocab_check:\n",
        "                out.append(variant)\n",
        "    return out"
      ],
      "metadata": {
        "id": "OQAdZMIjF01l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variants_word(word, place, mode=1):\n",
        "    \"\"\"\n",
        "    Generate word variants based on the input word and its position in the context.\n",
        "\n",
        "    Parameters:\n",
        "        word (str): The input word.\n",
        "        place (int): Position indicator.\n",
        "                     1 - Variant appears as the first word.\n",
        "                     2 - Variant appears as the second word.\n",
        "        mode (int): Mode for candidate generation.\n",
        "                    1 - Generate candidates with one correction.\n",
        "                    2 - Generate candidates with two corrections.\n",
        "\n",
        "    Returns:\n",
        "        list: List of word variants.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    variants = candidates_word(word) # looking for candidates with one correction\n",
        "    out = variants_word_calculate(variants, place) # checking that words can stand in a given place\n",
        "    if len(out) == 0:\n",
        "      # if there are no such words, then look for words with two corrections\n",
        "      variants = candidates_word(word, 2)\n",
        "      out = variants_word_calculate(variants, place)\n",
        "      if len(out) == 0:\n",
        "        # if there are no such words, we return the selected variants\n",
        "        out = variants\n",
        "    return out"
      ],
      "metadata": {
        "id": "tk75w0JOxuz9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# even if a word exists, I find possible words to replace it\n",
        "def alternatives_word(word, place):\n",
        "    \"\"\"\n",
        "    Generate alternative words based on the input word and its position in the context.\n",
        "\n",
        "    Parameters:\n",
        "        word (str): The input word.\n",
        "        place (int): Position indicator.\n",
        "                     1 - Word appears as the first word.\n",
        "                     2 - Word appears as the second word.\n",
        "\n",
        "    Returns:\n",
        "        list: List of alternative words.\n",
        "    \"\"\"\n",
        "    # Determine the threshold based on the position of the word in the vocabulary\n",
        "    if place == 1:\n",
        "      threshold = vocab_check_dict[(word, ' ')]\n",
        "    else:\n",
        "      threshold = vocab_check_dict[(' ', word)]\n",
        "    out = [word] # writing down the base word as it exists\n",
        "    alternatives = candidates_word(word)\n",
        "    for alternative in alternatives:\n",
        "        if place == 1:\n",
        "            if (alternative, ' ') in vocab_check:\n",
        "                if vocab_check_dict[(alternative, ' ')] > threshold:\n",
        "                    # checking that the alternative word is more common\n",
        "                    out.append(alternative)\n",
        "        else:\n",
        "            if (' ', alternative) in vocab_check:\n",
        "                if vocab_check_dict[(' ', alternative)] > threshold:\n",
        "                    out.append(alternative)\n",
        "    return out"
      ],
      "metadata": {
        "id": "L4TQa343FddH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(current_word, next_word, best_word, previous_word=None):\n",
        "    \"\"\"\n",
        "    Calculate how often the word is used in a given context\n",
        "\n",
        "    Parameters:\n",
        "        current_word (list): List of current word candidates.\n",
        "        next_word (list): List of next word candidates.\n",
        "        best_word (str): The best candidate word according to Norvig's solution.\n",
        "        previous_word (str): The previous word in the sequence. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples containing the candidate word, its cost, and possible next words.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    for f_word in current_word:\n",
        "        cost = 0\n",
        "        next_possible_words = []\n",
        "        if f_word == best_word:\n",
        "            # Add cost for the best word\n",
        "            cost += 1000\n",
        "        # Calculate cost based on bigram probabilities\n",
        "        for s_word in next_word:\n",
        "            if (f_word, s_word) in bigram_dict:\n",
        "                cost += bigram_dict[(f_word, s_word)]\n",
        "                next_possible_words.append(s_word) # add next possible word\n",
        "        # If no valid next word found, consider all next words\n",
        "        if len(next_possible_words) == 0:\n",
        "            next_possible_words.extend(next_word)\n",
        "        # Add cost based on previous word\n",
        "        if previous_word is not None:\n",
        "            if (previous_word, f_word) in bigram_dict:\n",
        "                cost += bigram_dict[(previous_word, f_word)] + 1000\n",
        "        # Append candidate with its cost and possible next words\n",
        "        candidates.append((f_word, cost, next_possible_words))\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "pjeX01fX-SKG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word(current_word, next_word, best_word, previous_word=None):\n",
        "    \"\"\"\n",
        "    Find the word with the highest score among the candidates.\n",
        "\n",
        "    Parameters:\n",
        "        current_word (list): List of current word candidates.\n",
        "        next_word (list): List of next word candidates.\n",
        "        best_word (str): The best candidate word according to Norvig's solution.\n",
        "        previous_word (str): The previous word in the sequence. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the selected word and possible next words.\n",
        "    \"\"\"\n",
        "    candidates = calculate(current_word, next_word, best_word, previous_word=previous_word)\n",
        "    # Sort candidates by cost in descending order and select the top one\n",
        "    candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[0]\n",
        "    return candidates[0], candidates[2]"
      ],
      "metadata": {
        "id": "__15yvTz7cz2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_word(previous_word, current_word):\n",
        "    \"\"\"\n",
        "    Determine the last word based on the previous word and current word candidates.\n",
        "\n",
        "    Parameters:\n",
        "        previous_word (str): The previous word in the sequence.\n",
        "        current_word (list): List of current word candidates.\n",
        "\n",
        "    Returns:\n",
        "        str: The selected last word.\n",
        "    \"\"\"\n",
        "    max_k = 0\n",
        "    max_word = ''\n",
        "    # Find the word with the highest bigram probability\n",
        "    for word in current_word:\n",
        "        if (previous_word, word) in bigram_dict:\n",
        "            k = bigram_dict[(previous_word, word)]\n",
        "            if k > max_k:\n",
        "                max_k = k\n",
        "                max_word = word\n",
        "    # If no word found based on bigram probability, select the word with the highest unigram probability\n",
        "    if max_k == 0:\n",
        "        for word in current_word:\n",
        "            if (previous_word, word) in bigram_dict:\n",
        "                k = vocab_check_dict[(' ', word)]\n",
        "                if k > max_k:\n",
        "                    max_k = k\n",
        "                    max_word = word\n",
        "    # If still no word found, select the first word in the list of candidates\n",
        "    if max_k == 0:\n",
        "        max_word = current_word[0]\n",
        "    return max_word"
      ],
      "metadata": {
        "id": "HXY5EYA0IcbZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spelling_corrector_ngram(sentence):\n",
        "    \"\"\"\n",
        "    Correct spelling in a sentence using an bigram based approach.\n",
        "\n",
        "    Parameters:\n",
        "        sentence (str): The input sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The corrected sentence.\n",
        "    \"\"\"\n",
        "    sentence_arr = sentence.lower().split()\n",
        "    new_sentence = []\n",
        "    for i in range(len(sentence_arr) - 1):\n",
        "        if i == 0:\n",
        "            # Determine alternatives or variants for the first word\n",
        "            if (sentence_arr[i], ' ') not in vocab_check:\n",
        "                new_sentence.append(variants_word(sentence_arr[i], 1))\n",
        "            else:\n",
        "                new_sentence.append(alternatives_word(sentence_arr[i], 1))\n",
        "        # Determine alternatives or variants for the next word\n",
        "        if (' ', sentence_arr[i + 1]) not in vocab_check:\n",
        "            new_sentence.append(variants_word(sentence_arr[i + 1], 2))\n",
        "        else:\n",
        "            new_sentence.append(alternatives_word(sentence_arr[i + 1], 2))\n",
        "        # Find the best word based on the context\n",
        "        if i != 0:\n",
        "            new_sentence[i], new_sentence[i + 1] = find_word(new_sentence[i], new_sentence[i + 1], correction(sentence_arr[i]), new_sentence[i - 1])\n",
        "        else:\n",
        "            new_sentence[i], new_sentence[i + 1] = find_word(new_sentence[i], new_sentence[i + 1], correction(sentence_arr[i]))\n",
        "\n",
        "        # Find the last word based on the previous word\n",
        "        if i == len(sentence_arr) - 2:\n",
        "            new_sentence[i+1] = last_word(new_sentence[i], new_sentence[i + 1])\n",
        "\n",
        "    return ' '.join(new_sentence)"
      ],
      "metadata": {
        "id": "ZasQKM_yNpUl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "My solution is built on a modified bigram. I consider not only context between two words but also look at previous word to ensure that the word fits the context. This can help where the previous word strongly influences the choice of the current word. Also, Instead of just considering pairs of words, I look how one word combines with different variations of the next word. I looking for options based on the frequency of word combinations and their fitness with the previous context. This approach allows me to consider that the chosen word not only occurs frequently, but also fits well into the sentence context.\n",
        "\n",
        "For example,\n",
        "\n",
        "'I wnnt o neet with fried' (I want to meet with friends)\n",
        "\n",
        "1. ['i', 'it', 'is'] + ['want', 'went'] - possible first and second words\n",
        "2. ('i', 'want') + ('i', 'went') = 8000, ('it', 'want') + ('it', 'went') = 700, ('is', 'want') + ('is', 'went') = 0 - based on the following variations, which word would be better fit\n",
        "3. 'i' + ['want', 'went'] + ['of', 'to', 'on'] - put the most frequently used word, and now the next word is being considered\n",
        "4. ('i', 'want') + ('want', 'of') + ... + ('want', 'on') = 3000, ('i', 'went') + ('went', 'of') + ... + ('went', 'on') = 2000 - in all words except the first, expect that our current word should match the previous one\n",
        "5. etc.\n",
        "\n",
        "I provide incentives for words that fit well with the previous context and also consider the word suggested by Norvig's solution, potentially giving it higher priority.\n",
        "\n",
        "My solution differs from Norvig's by considering alternative words even if the current word exists. This flexibility allows for better adaptation to the context and potentially improves correction accuracy (function: alternative_word()).\n",
        "But my solution uses some functions from Norvig's solution to quickly find the correct words.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "xdy4fHICkoa9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [],
      "source": [
        "# sentences are randomly taken from https://www.memorysecrets.ru/english/en-texts.html\n",
        "sentences = ['Travelling to far countries is always a thrilling and interesting adventure',\n",
        "             'On vacation you forget the hustle and bustle of everyday life and your job',\n",
        "             'Vegetables have a tiny amount of calories and are very rich in fiber',\n",
        "             'Absolutely all people of every type around the world are not indifferent to the music.',\n",
        "             'A week ago I got sick with the simple cold and did not want to go to the doctor.',\n",
        "             'Choosing a future profession influences all the future life of a person',\n",
        "             'All of us remember their first books from childhood',\n",
        "             'Earlier the explorers discovered deserted islands with the beaches of fine sand.',\n",
        "             'Our planet is the only place where a human being might live',\n",
        "             'All girls and boys are required to wear a particular uniform.']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = []\n",
        "for sentence in sentences:\n",
        "    for _ in range(5):\n",
        "        new_sentence = []\n",
        "        for word in sentence.split():\n",
        "            # Introduce spelling errors with a probability of 80%\n",
        "            if random.random() > 0.2:\n",
        "                # Decide whether to make a simple edit (40%) or a more complex edit (60%)\n",
        "                if random.random() > 0.6:\n",
        "                    v = list(edits1(word))\n",
        "                else:\n",
        "                    v = list(edits2(word))\n",
        "                new_sentence.append(random.choice(v))  # Randomly select an edit from the list\n",
        "            else:\n",
        "                new_sentence.append(word)\n",
        "        test_dataset.append((' '.join(new_sentence), sentence.lower()))\n",
        "\n",
        "test_dataset[4:9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEspfQ9EjJZ3",
        "outputId": "ca47419c-cc66-42f9-e6fb-43eea78880b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Tsravelling rto fari countrxbes his alwfns fwa thrifuling and pnterestjing aduventure',\n",
              "  'travelling to far countries is always a thrilling and interesting adventure'),\n",
              " ('dObn vacativon yizou bforget tjhf huztle anud blsktle ef everyday life jsnd yeodr jrob',\n",
              "  'on vacation you forget the hustle and bustle of everyday life and your job'),\n",
              " ('Ojn valcaion you forgetwj tje wustle awd bustlaa cpf everyady life annd yourq jonsb',\n",
              "  'on vacation you forget the hustle and bustle of everyday life and your job'),\n",
              " ('On tvacatizn yen fqorget the hustqle dnsd beustlbe bojf everyday liqe gnd you jdoh',\n",
              "  'on vacation you forget the hustle and bustle of everyday life and your job'),\n",
              " ('Oonc nvacation kaou forgqt tvhe hutstle and buwstlei foo severyday life aedo youm jhb',\n",
              "  'on vacation you forget the hustle and bustle of everyday life and your job')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def similar(pred, target):\n",
        "    return SequenceMatcher(None, pred, target).ratio()"
      ],
      "metadata": {
        "id": "_vdn5OY4mK2W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_similar = []\n",
        "norvig_similar = []\n",
        "for sentence in test_dataset:\n",
        "\n",
        "    print('A sentence with an error:', sentence[0])\n",
        "    ngram = spelling_corrector_ngram(sentence[0])\n",
        "    norvig = spelling_corrector_norvig(sentence[0])\n",
        "\n",
        "\n",
        "    ngram_similar.append(similar(ngram, sentence[1]))\n",
        "    norvig_similar.append(similar(norvig, sentence[1]))\n",
        "\n",
        "\n",
        "    print('A sentence corrected using Ngram:\\n', ngram, '\\nScore (ngram):', ngram_similar[-1])\n",
        "    print('A sentence corrected using Norvig:\\n', norvig, '\\nScore (norvig):', norvig_similar[-1])\n",
        "    print('A correct sentence:', sentence[1] + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofh33y5foe1R",
        "outputId": "1da47b5d-d414-4c68-fa78-5ed66785d2d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sentence with an error: Tratevlling ho acar csuntiries gsw aalvays oao thrilling anqy interesytcng asventure\n",
            "A sentence corrected using Ngram:\n",
            " travelling to scar countries is always oak thrilling any interesting adventure \n",
            "Score (ngram): 0.954248366013072\n",
            "A sentence corrected using Norvig:\n",
            " travelling ho scar countries is always oak thrilling any interesting adventure \n",
            "Score (norvig): 0.9411764705882353\n",
            "A correct sentence: travelling to far countries is always a thrilling and interesting adventure\n",
            "\n",
            "A sentence with an error: Traveleidg nto far countries oixs ahsways nv rthrildling and tnteresting advewnturx\n",
            "A sentence corrected using Ngram:\n",
            " traveled to war countries oils always no thrilling and interesting adventure \n",
            "Score (ngram): 0.9139072847682119\n",
            "A sentence corrected using Norvig:\n",
            " traveling to far countries oils always no thrilling and interesting adventure \n",
            "Score (norvig): 0.9605263157894737\n",
            "A correct sentence: travelling to far countries is always a thrilling and interesting adventure\n",
            "\n",
            "A sentence with an error: Trapelling tbo iaa dcountrkies nu always a thrillong anzd inuteresting adevntyre\n",
            "A sentence corrected using Ngram:\n",
            " travelling to ida countries no always a thrilling and interesting adventure \n",
            "Score (ngram): 0.9466666666666667\n",
            "A sentence corrected using Norvig:\n",
            " travelling to isa countries no always a thrilling and interesting adventure \n",
            "Score (norvig): 0.9466666666666667\n",
            "A correct sentence: travelling to far countries is always a thrilling and interesting adventure\n",
            "\n",
            "A sentence with an error: Traivellilg gto fwpr countwips is always a thrillinpg fnd intgretsing aventuren\n",
            "A sentence corrected using Ngram:\n",
            " travelling to four countries is always a thrilling and interesting ventures \n",
            "Score (ngram): 0.96\n",
            "A sentence corrected using Norvig:\n",
            " travelling to for countries is always a thrilling and interesting adventure \n",
            "Score (norvig): 0.9866666666666667\n",
            "A correct sentence: travelling to far countries is always a thrilling and interesting adventure\n",
            "\n",
            "A sentence with an error: Tsravelling rto fari countrxbes his alwfns fwa thrifuling and pnterestjing aduventure\n",
            "A sentence corrected using Ngram:\n",
            " travelling to far countries is always fwa trifling and interesting adventure \n",
            "Score (ngram): 0.9668874172185431\n",
            "A sentence corrected using Norvig:\n",
            " travelling to far countries his always fwo trifling and interesting adventure \n",
            "Score (norvig): 0.9473684210526315\n",
            "A correct sentence: travelling to far countries is always a thrilling and interesting adventure\n",
            "\n",
            "A sentence with an error: dObn vacativon yizou bforget tjhf huztle anud blsktle ef everyday life jsnd yeodr jrob\n",
            "A sentence corrected using Ngram:\n",
            " down vacation you forget the subtle and bustle of everyday life and your job \n",
            "Score (ngram): 0.96\n",
            "A sentence corrected using Norvig:\n",
            " down vacation you forget the subtle and bustle of everyday life and your job \n",
            "Score (norvig): 0.96\n",
            "A correct sentence: on vacation you forget the hustle and bustle of everyday life and your job\n",
            "\n",
            "A sentence with an error: Ojn valcaion you forgetwj tje wustle awd bustlaa cpf everyady life annd yourq jonsb\n",
            "A sentence corrected using Ngram:\n",
            " on vacation you forget the rustle and bustle cf everyday life and your job \n",
            "Score (ngram): 0.972972972972973\n",
            "A sentence corrected using Norvig:\n",
            " on vacation you forget the rustle and bustle cf everyday life and your sons \n",
            "Score (norvig): 0.9395973154362416\n",
            "A correct sentence: on vacation you forget the hustle and bustle of everyday life and your job\n",
            "\n",
            "A sentence with an error: On tvacatizn yen fqorget the hustqle dnsd beustlbe bojf everyday liqe gnd you jdoh\n",
            "A sentence corrected using Ngram:\n",
            " on vacation men forget the hostile and bustle of everyday life and you do \n",
            "Score (ngram): 0.9115646258503401\n",
            "A sentence corrected using Norvig:\n",
            " on vacation men forget the hostile and bustle of everyday like and you do \n",
            "Score (norvig): 0.8979591836734694\n",
            "A correct sentence: on vacation you forget the hustle and bustle of everyday life and your job\n",
            "\n",
            "A sentence with an error: Oonc nvacation kaou forgqt tvhe hutstle and buwstlei foo severyday life aedo youm jhb\n",
            "A sentence corrected using Ngram:\n",
            " on vacation you forget the rustle and bustle foo everyday life ado your job \n",
            "Score (ngram): 0.9530201342281879\n",
            "A sentence corrected using Norvig:\n",
            " donc vacation you forget the rustle and bustle foo everyday life ado you job \n",
            "Score (norvig): 0.9333333333333333\n",
            "A correct sentence: on vacation you forget the hustle and bustle of everyday life and your job\n",
            "\n",
            "A sentence with an error: id vachation yor firgeto the hushlew awind bustle ejof evveryday lvife bne youreu jxorb\n",
            "A sentence corrected using Ngram:\n",
            " id vacation for forget the hushed wind bustle of everyday life be your job \n",
            "Score (ngram): 0.8648648648648649\n",
            "A sentence corrected using Norvig:\n",
            " id vacation for forget the hushed wind bustle of everyday life be your job \n",
            "Score (norvig): 0.8648648648648649\n",
            "A correct sentence: on vacation you forget the hustle and bustle of everyday life and your job\n",
            "\n",
            "A sentence with an error: Vegetsables have ap oony amount wf calorqiues ajnkd are veary rich iln xicer\n",
            "A sentence corrected using Ngram:\n",
            " vegetables have a bony amount of calorqiues and are very rich in nicer \n",
            "Score (ngram): 0.927536231884058\n",
            "A sentence corrected using Norvig:\n",
            " vegetables have a bony amount of calorqiues and are very rich in nicer \n",
            "Score (norvig): 0.927536231884058\n",
            "A correct sentence: vegetables have a tiny amount of calories and are very rich in fiber\n",
            "\n",
            "A sentence with an error: Vegetables hame a tgny amount vxof calprixes snd sere very rich iunw fibekr\n",
            "A sentence corrected using Ngram:\n",
            " vegetables have a tiny amount of caprices and were very rich in fiver \n",
            "Score (ngram): 0.9343065693430657\n",
            "A sentence corrected using Norvig:\n",
            " vegetables have a tiny amount of caprices and were very rich in finer \n",
            "Score (norvig): 0.9343065693430657\n",
            "A correct sentence: vegetables have a tiny amount of calories and are very rich in fiber\n",
            "\n",
            "A sentence with an error: Veketablmes havse naf tinyv amoaunt gkf caloaies qanzd aire very rich tna fibxr\n",
            "A sentence corrected using Ngram:\n",
            " vegetables have nap tiny amount of colonies and are very rich tea fibre \n",
            "Score (ngram): 0.9064748201438849\n",
            "A sentence corrected using Norvig:\n",
            " vegetables have nap tiny amount of colonies and are very rich tea fix \n",
            "Score (norvig): 0.8905109489051095\n",
            "A correct sentence: vegetables have a tiny amount of calories and are very rich in fiber\n",
            "\n",
            "A sentence with an error: Vegetables havl wa tqdny arount bf caloriew anbd arseu avvry richa sit fiter\n",
            "A sentence corrected using Ngram:\n",
            " vegetables have a tiny amount of calorie and are very rich set finer \n",
            "Score (ngram): 0.9411764705882353\n",
            "A sentence corrected using Norvig:\n",
            " vegetables have wa today around of calorie and are very rich sit finer \n",
            "Score (norvig): 0.8840579710144928\n",
            "A correct sentence: vegetables have a tiny amount of calories and are very rich in fiber\n",
            "\n",
            "A sentence with an error: Vegeuablves havec va tiny amount of cajorives and aqre veryn ryich irn yfzber\n",
            "A sentence corrected using Ngram:\n",
            " vegetables have a tiny amount of cajorives and are very rich in yfzber \n",
            "Score (ngram): 0.9565217391304348\n",
            "A sentence corrected using Norvig:\n",
            " vegetables have va tiny amount of cajorives and are very rich in yfzber \n",
            "Score (norvig): 0.9496402877697842\n",
            "A correct sentence: vegetables have a tiny amount of calories and are very rich in fiber\n",
            "\n",
            "A sentence with an error: Absolytely alel pcbople of eyvery type arsvound ltoe woozld are noatr indifferent zo te mhusic.\n",
            "A sentence corrected using Ngram:\n",
            " absolutely all people of every type around toe world are not indifferent to the music \n",
            "Score (ngram): 0.9824561403508771\n",
            "A sentence corrected using Norvig:\n",
            " absolutely all people of every type around toe would are not indifferent to te music \n",
            "Score (norvig): 0.9647058823529412\n",
            "A correct sentence: absolutely all people of every type around the world are not indifferent to the music.\n",
            "\n",
            "A sentence with an error: Absolutelry aall people xjof every cvype around the worqd eare nout indiffprent gtz the mvusec.\n",
            "A sentence corrected using Ngram:\n",
            " absolutely all people of every type around the world are not indifferent to the mvusec. \n",
            "Score (ngram): 0.9826589595375722\n",
            "A sentence corrected using Norvig:\n",
            " absolutely all people of every type around the world are not indifferent tz the mvusec. \n",
            "Score (norvig): 0.9710982658959537\n",
            "A correct sentence: absolutely all people of every type around the world are not indifferent to the music.\n",
            "\n",
            "A sentence with an error: Absolutegly wavl pegpsle rojf eveakry tvjpe aurouyd the wimld irl not indifferennt jto thxe music.e\n",
            "A sentence corrected using Ngram:\n",
            " absolutely wall people roof every type around the wild girl not indifferent to the music \n",
            "Score (ngram): 0.9310344827586207\n",
            "A sentence corrected using Norvig:\n",
            " absolutely wall people roof every type around the wild girl not indifferent to the muscle \n",
            "Score (norvig): 0.9142857142857143\n",
            "A correct sentence: absolutely all people of every type around the world are not indifferent to the music.\n",
            "\n",
            "A sentence with an error: Absolgutely all people of eoerc type around ftht pwohld ares not indifferednt tr dthe music.\n",
            "A sentence corrected using Ngram:\n",
            " absolutely all people of every type around the world are not indifferent to the music \n",
            "Score (ngram): 0.9941520467836257\n",
            "A sentence corrected using Norvig:\n",
            " absolutely all people of every type around the would are not indifferent tr the music \n",
            "Score (norvig): 0.9707602339181286\n",
            "A correct sentence: absolutely all people of every type around the world are not indifferent to the music.\n",
            "\n",
            "A sentence with an error: rAbsolutely arll people omn evmry type around tghep worldp are dst indiffereno son the muscec.\n",
            "A sentence corrected using Ngram:\n",
            " absolutely all people on every type around the world are st indifferent on the muscec. \n",
            "Score (ngram): 0.9418604651162791\n",
            "A sentence corrected using Norvig:\n",
            " absolutely all people on every type around the world are st indifferent son the muscec. \n",
            "Score (norvig): 0.9364161849710982\n",
            "A correct sentence: absolutely all people of every type around the world are not indifferent to the music.\n",
            "\n",
            "A sentence with an error: Auk wefesk agwod Iy got sigk with lwhe sicple coclh and diae osnot qwant qto goqk tmw thfep doctor.x\n",
            "A sentence corrected using Ngram:\n",
            " ask weeks ago is not sign with the simple cold and die not want to go tm the doctor \n",
            "Score (ngram): 0.9079754601226994\n",
            "A sentence corrected using Norvig:\n",
            " ask weeks good in got sign with the simple could and die not want to go tm the doctor \n",
            "Score (norvig): 0.896969696969697\n",
            "A correct sentence: a week ago i got sick with the simple cold and did not want to go to the doctor.\n",
            "\n",
            "A sentence with an error: Ae week agrt lf got sick wbtho etihe simple csold ancjd dcpd notp wuaut td cou ej th doctor.\n",
            "A sentence corrected using Ngram:\n",
            " a week art if not sick with the simple cold and did not want to you e the doctor \n",
            "Score (ngram): 0.9125\n",
            "A sentence corrected using Norvig:\n",
            " a week art of got sick with the simple cold and did not what to you e th doctor \n",
            "Score (norvig): 0.8930817610062893\n",
            "A correct sentence: a week ago i got sick with the simple cold and did not want to go to the doctor.\n",
            "\n",
            "A sentence with an error: lmA vieek auigo wI got sick wutuh the qsimple coqv handu daiy nmoq whvant tor go tko hthe doctomg.\n",
            "A sentence corrected using Ngram:\n",
            " la vie ago i got sick with the simple come hand day not want to do to the doctomg. \n",
            "Score (ngram): 0.8765432098765432\n",
            "A sentence corrected using Norvig:\n",
            " la view ago i got sick with the simple come hand day not what to go to the doctomg. \n",
            "Score (norvig): 0.8711656441717791\n",
            "A correct sentence: a week ago i got sick with the simple cold and did not want to go to the doctor.\n",
            "\n",
            "A sentence with an error: xA weeqc aago Itk got sjdck with te semplf wctold and tdid noh gwant tr efgo bw lhbe bdoctor.\n",
            "A sentence corrected using Ngram:\n",
            " a week ago it got stuck with the sample cold and did not want to ego by the doctor \n",
            "Score (ngram): 0.9259259259259259\n",
            "A sentence corrected using Norvig:\n",
            " a weeks ago it got shock with te semple told and did not want tr ego by the doctor \n",
            "Score (norvig): 0.8888888888888888\n",
            "A correct sentence: a week ago i got sick with the simple cold and did not want to go to the doctor.\n",
            "\n",
            "A sentence with an error: Ae rweek agoa Ioh gotg sick wxtnh lthe svimpue dbold amjnd vid nft want rton go dato twhe dxoctor.\n",
            "A sentence corrected using Ngram:\n",
            " a week ago oh got sick with the simple bold amend did not want ton to date the doctor \n",
            "Score (ngram): 0.896969696969697\n",
            "A sentence corrected using Norvig:\n",
            " a week ago oh got sick with the simple bold amend did not want ton go dato the doctor \n",
            "Score (norvig): 0.9333333333333333\n",
            "A correct sentence: a week ago i got sick with the simple cold and did not want to go to the doctor.\n",
            "\n",
            "A sentence with an error: Chogosing awc fugiure pkrofhession inclfuences alll the fxuture liioe gkf ma pekrsog\n",
            "A sentence corrected using Ngram:\n",
            " choosing awe future profession influences all the future life of a person \n",
            "Score (ngram): 0.9861111111111112\n",
            "A sentence corrected using Norvig:\n",
            " choosing awe future profession influences all the future like of ma person \n",
            "Score (norvig): 0.9655172413793104\n",
            "A correct sentence: choosing a future profession influences all the future life of a person\n",
            "\n",
            "A sentence with an error: zhoocing tai fuvure profqession inflhencevs alvlc othe futgure lqize oj ua personf\n",
            "A sentence corrected using Ngram:\n",
            " choosing tax future profession influences all the future life of a person \n",
            "Score (ngram): 0.9861111111111112\n",
            "A sentence corrected using Norvig:\n",
            " choosing tax future profession influences all the future like of a person \n",
            "Score (norvig): 0.9722222222222222\n",
            "A correct sentence: choosing a future profession influences all the future life of a person\n",
            "\n",
            "A sentence with an error: Chooseipng amg futuveu hrofesaion influences gnll dthf future life bhof av prqerson\n",
            "A sentence corrected using Ngram:\n",
            " choosing am future profession influences gall the future life of a person \n",
            "Score (ngram): 0.9861111111111112\n",
            "A sentence corrected using Norvig:\n",
            " choosing am future profession influences gall the future life of a person \n",
            "Score (norvig): 0.9861111111111112\n",
            "A correct sentence: choosing a future profession influences all the future life of a person\n",
            "\n",
            "A sentence with an error: buoosing ar cvuture profession isnfluencen adllp tyhe futuee olife ocx aus person\n",
            "A sentence corrected using Ngram:\n",
            " choosing a couture profession influence all the future life ox as person \n",
            "Score (ngram): 0.951048951048951\n",
            "A sentence corrected using Norvig:\n",
            " choosing ar couture profession influence all the future life ox as person \n",
            "Score (norvig): 0.9444444444444444\n",
            "A correct sentence: choosing a future profession influences all the future life of a person\n",
            "\n",
            "A sentence with an error: ahoosinb a funzure profession inflouences ull the future life kdf ae pgeraon\n",
            "A sentence corrected using Ngram:\n",
            " choosing a future profession influences all the future life of a person \n",
            "Score (ngram): 1.0\n",
            "A sentence corrected using Norvig:\n",
            " choosing a future profession influences all the future life of a person \n",
            "Score (norvig): 1.0\n",
            "A correct sentence: choosing a future profession influences all the future life of a person\n",
            "\n",
            "A sentence with an error: All of tms regembjr thceir kfirst shooks frm cllidhood\n",
            "A sentence corrected using Ngram:\n",
            " all of tm remember their first shook from childhood \n",
            "Score (ngram): 0.9215686274509803\n",
            "A sentence corrected using Norvig:\n",
            " all of tm remember their first shook from childhood \n",
            "Score (norvig): 0.9215686274509803\n",
            "A correct sentence: all of us remember their first books from childhood\n",
            "\n",
            "A sentence with an error: Alla og tks rlemember theicm firfsti booas prom chnildhood\n",
            "A sentence corrected using Ngram:\n",
            " all of tss remember their first books from childhood \n",
            "Score (ngram): 0.970873786407767\n",
            "A sentence corrected using Norvig:\n",
            " all of tis remember their first boots from childhood \n",
            "Score (norvig): 0.9514563106796117\n",
            "A correct sentence: all of us remember their first books from childhood\n",
            "\n",
            "A sentence with an error: pAln opk ups rejrmber wthebir nirsb bohhoks from chilphzod\n",
            "A sentence corrected using Ngram:\n",
            " pain oak up remember their first books from childhood \n",
            "Score (ngram): 0.9038461538461539\n",
            "A sentence corrected using Norvig:\n",
            " pain oak up remember their first books from childhood \n",
            "Score (norvig): 0.9038461538461539\n",
            "A correct sentence: all of us remember their first books from childhood\n",
            "\n",
            "A sentence with an error: All ofco sus remevber trheirh cirsvt abookrs fyomz childhood\n",
            "A sentence corrected using Ngram:\n",
            " all of us remember their first books from childhood \n",
            "Score (ngram): 1.0\n",
            "A sentence corrected using Norvig:\n",
            " all of us remember their first books from childhood \n",
            "Score (norvig): 1.0\n",
            "A correct sentence: all of us remember their first books from childhood\n",
            "\n",
            "A sentence with an error: Algo ifd us remember nheir jfirst boeokso from cuildhood\n",
            "A sentence corrected using Ngram:\n",
            " also if us remember their first books from childhood \n",
            "Score (ngram): 0.9514563106796117\n",
            "A sentence corrected using Norvig:\n",
            " also if us remember their first books from childhood \n",
            "Score (norvig): 0.9514563106796117\n",
            "A correct sentence: all of us remember their first books from childhood\n",
            "\n",
            "A sentence with an error: Earqier them explorers jdiscoverea desetrted istazds wnith ta byachee joof finpie tabnd.\n",
            "A sentence corrected using Ngram:\n",
            " earlier the explorers discovered deserted islands with a bache roof fine tabnd. \n",
            "Score (ngram): 0.9308176100628931\n",
            "A sentence corrected using Norvig:\n",
            " earlier them explorers discovered deserted islands with ta bache roof fine tabnd. \n",
            "Score (norvig): 0.9316770186335404\n",
            "A correct sentence: earlier the explorers discovered deserted islands with the beaches of fine sand.\n",
            "\n",
            "A sentence with an error: Earlisry athk expzoreos dicscovered dpsprted ielands itdh thle beaches foz finne sand.\n",
            "A sentence corrected using Ngram:\n",
            " earlier the explorers discovered deserted islands with the reaches for fine sand \n",
            "Score (ngram): 0.9625\n",
            "A sentence corrected using Norvig:\n",
            " earlier the explorers discovered deserted islands it the reaches for fine sand \n",
            "Score (norvig): 0.9493670886075949\n",
            "A correct sentence: earlier the explorers discovered deserted islands with the beaches of fine sand.\n",
            "\n",
            "A sentence with an error: yarlier tgje expaorqers discovehed desergted imaands with rtge beaches of feine sandi\n",
            "A sentence corrected using Ngram:\n",
            " earlier the explorers discovered deserted islands with rage reaches of fine sand \n",
            "Score (ngram): 0.95\n",
            "A sentence corrected using Norvig:\n",
            " earlier the explorers discovered deserted islands with rage reaches of fine sand \n",
            "Score (norvig): 0.95\n",
            "A correct sentence: earlier the explorers discovered deserted islands with the beaches of fine sand.\n",
            "\n",
            "A sentence with an error: Earticr the egxplorergs discovered dsenrted ieslands wtih the lbeawhes of finkxe sxnwd.\n",
            "A sentence corrected using Ngram:\n",
            " earlier the explorers discovered deserted islands with the leashes of fine sxnwd. \n",
            "Score (ngram): 0.9565217391304348\n",
            "A sentence corrected using Norvig:\n",
            " earlier the explorers discovered deserted islands with the leashes of fine sxnwd. \n",
            "Score (norvig): 0.9565217391304348\n",
            "A correct sentence: earlier the explorers discovered deserted islands with the beaches of fine sand.\n",
            "\n",
            "A sentence with an error: Earwliey tme expluorers discoovered desewrtked islandsu wiath tfhe beazhes ol zfine fsand.\n",
            "A sentence corrected using Ngram:\n",
            " earlier the explorers discovered deserted islands with the reaches of fine sand \n",
            "Score (ngram): 0.9811320754716981\n",
            "A sentence corrected using Norvig:\n",
            " earlier the explorers discovered deserted islands with the reaches of fine sand \n",
            "Score (norvig): 0.9811320754716981\n",
            "A correct sentence: earlier the explorers discovered deserted islands with the beaches of fine sand.\n",
            "\n",
            "A sentence with an error: Ouy planet ibs the tonny plaet where a humafn beini rmigeht live\n",
            "A sentence corrected using Ngram:\n",
            " our planet is the tony plate were a human being right like \n",
            "Score (ngram): 0.9230769230769231\n",
            "A sentence corrected using Norvig:\n",
            " out planet is the bonny plate where a human being right live \n",
            "Score (norvig): 0.9243697478991597\n",
            "A correct sentence: our planet is the only place where a human being might live\n",
            "\n",
            "A sentence with an error: Ourv planet ids theb only placex wehede rpa humrn beind migiht lmvxe\n",
            "A sentence corrected using Ngram:\n",
            " our planet is the only place where pa human being might live \n",
            "Score (ngram): 0.9915966386554622\n",
            "A sentence corrected using Norvig:\n",
            " our planet is the only place where pa human being might love \n",
            "Score (norvig): 0.9747899159663865\n",
            "A correct sentence: our planet is the only place where a human being might live\n",
            "\n",
            "A sentence with an error: Owubr plianhet ijsq tahe oynlfy place where qo hulaen beigan gmight live\n",
            "A sentence corrected using Ngram:\n",
            " our planet is the only place were to human began might like \n",
            "Score (ngram): 0.9152542372881356\n",
            "A sentence corrected using Norvig:\n",
            " our planet is the only place where to human began might live \n",
            "Score (norvig): 0.9411764705882353\n",
            "A correct sentence: our planet is the only place where a human being might live\n",
            "\n",
            "A sentence with an error: Ouz pqanhet isvs twe onlyu place were ac huhany being mbifht ieve\n",
            "A sentence corrected using Ngram:\n",
            " out planet iss the only place were a human being might eve \n",
            "Score (ngram): 0.9401709401709402\n",
            "A sentence corrected using Norvig:\n",
            " out planet iss the only place were ac human being might eve \n",
            "Score (norvig): 0.9322033898305084\n",
            "A correct sentence: our planet is the only place where a human being might live\n",
            "\n",
            "A sentence with an error: Orr planset is the rnlyd plabceg whiere vau fhwman being miihto liven\n",
            "A sentence corrected using Ngram:\n",
            " or planet in the only place where van human being might live \n",
            "Score (ngram): 0.957983193277311\n",
            "A sentence corrected using Norvig:\n",
            " or planet is the only place where van human being might given \n",
            "Score (norvig): 0.95\n",
            "A correct sentence: our planet is the only place where a human being might live\n",
            "\n",
            "A sentence with an error: Alml gigfls and kboys agrue reqsuirevd to twar q parjicular uniform.\n",
            "A sentence corrected using Ngram:\n",
            " all girls and boys agree required to war a particular uniform \n",
            "Score (ngram): 0.9672131147540983\n",
            "A sentence corrected using Norvig:\n",
            " all girls and boys agree required to war q particular uniform \n",
            "Score (norvig): 0.9508196721311475\n",
            "A correct sentence: all girls and boys are required to wear a particular uniform.\n",
            "\n",
            "A sentence with an error: All zgirdls xnd bocys gare requiqred fo wear arj pjrtimcular cnimform.\n",
            "A sentence corrected using Ngram:\n",
            " all girls and boys are required to hear are particular cnimform. \n",
            "Score (ngram): 0.944\n",
            "A sentence corrected using Norvig:\n",
            " all girls and boys gare required fo wear are particular cnimform. \n",
            "Score (norvig): 0.9365079365079365\n",
            "A correct sentence: all girls and boys are required to wear a particular uniform.\n",
            "\n",
            "A sentence with an error: rll wirlsa anz boyss rare onequired toy vear w parsticulan uniform.\n",
            "A sentence corrected using Ngram:\n",
            " all girls and boys are required to hear a particular uniform \n",
            "Score (ngram): 0.9752066115702479\n",
            "A sentence corrected using Norvig:\n",
            " all girls and boys rare required toy dear w particular uniform \n",
            "Score (norvig): 0.943089430894309\n",
            "A correct sentence: all girls and boys are required to wear a particular uniform.\n",
            "\n",
            "A sentence with an error: Akll gipls axd boys areg requjred toy reamr a ipxarticular unifkormv.\n",
            "A sentence corrected using Ngram:\n",
            " all girls and boys are required to rear as particular unifkormv. \n",
            "Score (ngram): 0.96\n",
            "A sentence corrected using Norvig:\n",
            " all girls and boys are required toy rear a particular unifkormv. \n",
            "Score (norvig): 0.96\n",
            "A correct sentence: all girls and boys are required to wear a particular uniform.\n",
            "\n",
            "A sentence with an error: yll xgirtls andoz byys asre reruxred dvo wiar xq partyculyr unoform.j\n",
            "A sentence corrected using Ngram:\n",
            " all girls and boys are required do wear x particular unoform.j \n",
            "Score (ngram): 0.943089430894309\n",
            "A sentence corrected using Norvig:\n",
            " all girls and boys are required do war x particular unoform.j \n",
            "Score (norvig): 0.9344262295081968\n",
            "A correct sentence: all girls and boys are required to wear a particular uniform.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_ngram = sum(ngram_similar) / len(ngram_similar)\n",
        "acc_ngram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEyrhsTlqt53",
        "outputId": "e0869e5f-f38e-4d95-ccd2-a497e9bc6265"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9575582845646727"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_norvig = sum(norvig_similar) / len(norvig_similar)\n",
        "acc_norvig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjqppxsmrLLx",
        "outputId": "1fdb8e3a-9028-47f4-d79b-3f6116d3ea00"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93035239979529"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the sentences are not very complex and there are not many errors, both algorithms work well, but since my solution takes context into account, it produces better results with different generated sentences."
      ],
      "metadata": {
        "id": "3LL0C2aL1LzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMctfa0LyiSo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}